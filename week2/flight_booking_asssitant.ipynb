{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c57e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6b5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "openai = OpenAI()\n",
    "\n",
    "OPENAI_MODEL = \"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a821db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You are a helpful assistant. Your specialisation is to help customers book tickets. \n",
    "    You have a good knack of finding great offers to land customers in good deals.\n",
    "    You work for a company called Flight AI\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa49eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = {\n",
    "    \"bangalore\": \"5949\",\n",
    "    \"mumbai\": \"4500\",\n",
    "    \"delhi\": \"6200\",\n",
    "    \"chennai\": \"3800\",\n",
    "    \"kolkata\": \"7100\",\n",
    "    \"hyderabad\": \"4100\",\n",
    "    \"pune\": \"4700\",\n",
    "    \"goa\": \"5500\",\n",
    "    \"jaipur\": \"5800\",\n",
    "    \"ahmedabad\": \"4900\",\n",
    "    \"kochi\": \"3200\",\n",
    "    \"trivandrum\": \"3400\",\n",
    "    \"varanasi\": \"6700\",\n",
    "    \"lucknow\": \"6100\",\n",
    "    \"chandigarh\": \"6300\",\n",
    "    \"mysore\": \"5100\",\n",
    "    \"indore\": \"4300\",\n",
    "    \"surat\": \"4600\",\n",
    "    \"bhopal\": \"4400\",\n",
    "    \"patna\": \"6900\",\n",
    "    \"visakhapatnam\": \"5200\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aad675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticket_prices(destination_city):\n",
    "    print(f\"get_ticket_prices tool called. destination city -> {destination_city}\")\n",
    "    if destination_city is None or destination_city.strip() == \"\":\n",
    "        raise ValueError(\"Destination city cannot be None or blank\")\n",
    "    \n",
    "    price = ticket_prices.get(destination_city.lower(), f\"sorry, we do not operator to {destination_city}. ticket price not found\")\n",
    "\n",
    "    return f\"The price of a ticket to {destination_city} is {price}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d67702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a77406",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": ticket_price_tool}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8abc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_window_ui(user_message, history):\n",
    "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": user_message}]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "    \n",
    "    if response.choices[0].finish_reason == 'tool_calls':\n",
    "        tools_message = response.choices[0].message\n",
    "        tools_response = handle_tools_call(tools_message)\n",
    "        messages.append(tools_message)\n",
    "        messages.append(tools_response)\n",
    "\n",
    "        for message in messages:\n",
    "            print(message)\n",
    "            \n",
    "        response = openai.chat.completions.create(model=OPENAI_MODEL, messages=messages)\n",
    "        \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a473c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tools_call(tools_message):\n",
    "    \n",
    "    tool_call = tools_message.tool_calls[0]\n",
    "    tools_function = tool_call.function\n",
    "    tools_call_id = tool_call.id\n",
    "    \n",
    "    if tools_function.name == 'get_ticket_prices':\n",
    "        function_arguments = json.loads(tools_function.arguments)\n",
    "        destination_city = function_arguments.get(\"destination_city\", \"no city found\")\n",
    "        ticket_price_or_error = get_ticket_prices(destination_city=destination_city)\n",
    "        response = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": ticket_price_or_error,\n",
    "            \"tool_call_id\": tools_call_id\n",
    "        }\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9997e5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7933\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7933/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages before tools call -> [{'role': 'system', 'content': '\\n    You are a helpful assistant. Your specialisation is to help customers book tickets. \\n    You have a good knack of finding great offers to land customers in good deals.\\n    You work for a company called Flight AI\\n'}, {'role': 'user', 'content': 'book a ticket to trivandrum'}]\n",
      "abc => Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_elZL7o0V9FjCfKUa3ntlSGn4', function=Function(arguments='{\"destination_city\":\"trivandrum\"}', name='get_ticket_prices'), type='function')]))\n",
      "get_ticket_prices tool called. destination city -> trivandrum\n",
      "{'role': 'system', 'content': '\\n    You are a helpful assistant. Your specialisation is to help customers book tickets. \\n    You have a good knack of finding great offers to land customers in good deals.\\n    You work for a company called Flight AI\\n'}\n",
      "{'role': 'user', 'content': 'book a ticket to trivandrum'}\n",
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_elZL7o0V9FjCfKUa3ntlSGn4', function=Function(arguments='{\"destination_city\":\"trivandrum\"}', name='get_ticket_prices'), type='function')])\n",
      "{'role': 'tools', 'content': 'The price of a ticket to trivandrum is 3400', 'tool_call_id': 'call_elZL7o0V9FjCfKUa3ntlSGn4'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/gradio/queueing.py\", line 763, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/gradio/blocks.py\", line 2125, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/gradio/blocks.py\", line 1605, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/gradio/utils.py\", line 1033, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/gradio/chat_interface.py\", line 541, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/gradio/chat_interface.py\", line 902, in _submit_fn\n",
      "    response = await run_sync(self.fn, *inputs, limiter=self.limiter)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/anyio/to_thread.py\", line 61, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2525, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 986, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/qq/3lyvnrld7flcy8v745khsj3m0000gn/T/ipykernel_36769/357114159.py\", line 21, in chat_window_ui\n",
      "    response = openai.chat.completions.create(model=OPENAI_MODEL, messages=messages)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1192, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rijuvijayan/1workspace/learning/udemy/LLM_Engineering/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid value: 'tools'. Supported values are: 'system', 'assistant', 'user', 'function', 'tool', and 'developer'.\", 'type': 'invalid_request_error', 'param': 'messages[3].role', 'code': 'invalid_value'}}\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat_window_ui).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_Engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
